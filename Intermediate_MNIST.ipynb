{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermediate MNIST tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_14180\\1332836739.py:7: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import important libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' # For faster processing if you have a GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = (y_true == y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(results):\n",
    "    \n",
    "    loss = results[\"train_loss\"]\n",
    "    test_loss = results[\"test_loss\"]\n",
    "\n",
    "    accuracy = results[\"train_acc\"]\n",
    "    test_accuracy = results[\"test_acc\"]\n",
    "\n",
    "    epochs = range(len(results[\"train_loss\"]))\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, label=\"train_loss\")\n",
    "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
    "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_model(model_name, hidden_units):\n",
    "    if model_name == 'baseline':\n",
    "        return baseline_model()\n",
    "    elif model_name == 'ffn':\n",
    "        return FFN(hidden_units=hidden_units)\n",
    "    elif model_name == 'alexnet':\n",
    "        return AlexNet()\n",
    "    else:\n",
    "        return baseline_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load in the data and inspect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='data', train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Shape of each image in the training dataset: torch.Size([1, 28, 28])\n",
      "Shape of each image in the testing dataset: torch.Size([1, 28, 28])\n",
      "Number of classes: 10\n",
      "Classes: ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "# Basic information about the training and testing dataset\n",
    "print(f'Number of training samples: {len(train_dataset)}')\n",
    "print(f'Number of test samples: {len(test_dataset)}')\n",
    "img_train, label_train = train_dataset[0]\n",
    "img_test, label_test = test_dataset[0]\n",
    "print(f'Shape of each image in the training dataset: {img_train.shape}')\n",
    "print(f'Shape of each image in the testing dataset: {img_test.shape}')\n",
    "print(f'Number of classes: {len(train_dataset.classes)}')\n",
    "print(f'Classes: {train_dataset.classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at the class distribution. We want to identify whether the classes are balanced.\n",
    "train_labels_df = pd.DataFrame(train_dataset.targets.numpy(), columns=['label'])\n",
    "test_labels_df = pd.DataFrame(test_dataset.targets.numpy(), columns=['label'])\n",
    "\n",
    "def plot_class_distribution(labels_df, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(data=labels_df, x = 'label')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('frequency')\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(train_labels_df, 'Training Set Class Distribution')\n",
    "plot_class_distribution(test_labels_df, 'Testing Set Class Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the classes are slightly imbalanced. However, we can also observe that the imbalances are roughly similar in both datasets. This means that (at least for now) we do not have to account for the imbalances, as this imbalance also occurs in the test dataset - thus if the model does well on the imbalance in the training dataset, it hopefully also does on the testing dataset. Keep in mind that this is often not how it goes in real-life scenarios, i.e. the testing data is often not known/unavailable. This might also be important when we will augment the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We might want to set the seed to plot the same images\n",
    "torch.manual_seed(1230139)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "random_idx = torch.randint(low=0, high=len(train_dataset), size=[1]).item()\n",
    "img, label = train_dataset[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap='gray') \n",
    "plt.title(class_names[label])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without knowing the target, would you not have said this looks more like a 6 than a 5? From running the above code some times and changing the seed, we can see that most numbers look recognizable, but also that some are more difficult to guess than others. This is something we will have to take into account after our model has made predictions. It's always important to recognize that when our model makes mistakes, we *look* at these mistakes, because maybe we shouldn't call it a mistake:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline linear model\n",
    "We build a baseline linear model for comparing with later models. When we have built our pipeline we can easily compare our more complex models to this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(28*28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, 28*28))\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a training and evaluating loop. This should be generalizable for other models as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device=device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device) # We set the data to our device for faster computation.\n",
    "        y_pred = model(X) # We make the predictions\n",
    "\n",
    "        loss = loss_fn(y_pred, y) \n",
    "        acc = accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    # print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\")\n",
    "    \n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               device: torch.device=device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device) # We set the data to our device for faster computation.\n",
    "\n",
    "            y_pred = model(X) # We make the predictions\n",
    "\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            acc = accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "            test_loss += loss.item()\n",
    "            test_acc += acc\n",
    "\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        # print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we combine the training and testing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          val_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 10,\n",
    "          patience: int = 2,\n",
    "          device: torch.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')):\n",
    "    \n",
    "    model.to(device)\n",
    "    results = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": []\n",
    "    }\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           data_loader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        val_loss, val_acc = test_step(model=model,\n",
    "                                        data_loader=val_dataloader,\n",
    "                                        loss_fn=loss_fn)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1} | \"\n",
    "              f\"train_loss: {train_loss:.4f} | \"\n",
    "              f\"train_acc: {train_acc:.4f} | \"\n",
    "              f\"val_loss: {val_loss:.4f} | \"\n",
    "              f\"val_acc: {val_acc:.4f}\")\n",
    "\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"val_loss\"].append(val_loss)\n",
    "        results[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch \n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    return results, best_epoch, best_model_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will be incorporating k-fold cross-validation for a more robust measure of performance. This is especially important when we are doing hyperparameter tuning. We will also implement Early Stopping, a regularization method that constrains the number of epochs a model can train for. This has the potential to lead to better generalization and reduces training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "def cross_validation(k, train_dataset, model_name, batch_size=64, lr=0.1, hidden_units=128):\n",
    "    fold_results = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_acc\": []\n",
    "        }\n",
    "    \n",
    "    indices = list(range(len(train_dataset)))\n",
    "\n",
    "    if k == 1:\n",
    "        split_size = int(0.8 * len(train_dataset))\n",
    "        val_indices = indices[:split_size:]\n",
    "        train_indices = indices[:split_size]\n",
    "    else:\n",
    "        split_size = len(train_dataset) // k\n",
    "\n",
    "    for i in range(k):\n",
    "        print(f\"Fold {i+1}\")\n",
    "        \n",
    "        if k > 1:\n",
    "            val_indices = indices[i * split_size: (i + 1) * split_size] if (i + 1) != k else indices[i * split_size:]\n",
    "            train_indices = list(set(indices) - set(val_indices))\n",
    "\n",
    "        train_fold = Subset(train_dataset, train_indices)\n",
    "        val_fold = Subset(train_dataset, val_indices)\n",
    "\n",
    "        train_dataloader = DataLoader(train_fold, batch_size=batch_size, shuffle=True)\n",
    "        val_dataloader = DataLoader(val_fold, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        model = return_model(model_name, hidden_units=hidden_units) # Returns appropriate model based on name.\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        results, best_epoch, best_model_state = train(model=model, \n",
    "                        train_dataloader=train_dataloader, \n",
    "                        val_dataloader=val_dataloader,\n",
    "                        optimizer=optimizer,\n",
    "                        loss_fn=loss_fn,\n",
    "                        epochs=10,\n",
    "                        patience=2) \n",
    "        \n",
    "        fold_results[\"train_loss\"].append(results[\"train_loss\"][best_epoch])\n",
    "        fold_results[\"train_acc\"].append(results[\"train_acc\"][best_epoch])\n",
    "        fold_results[\"val_loss\"].append(results[\"val_loss\"][best_epoch])\n",
    "        fold_results[\"val_acc\"].append(results[\"val_acc\"][best_epoch])\n",
    "        \n",
    "    avg_train_loss = np.mean(fold_results[\"train_loss\"])\n",
    "    avg_train_acc = np.mean(fold_results[\"train_acc\"])\n",
    "    avg_val_loss = np.mean(fold_results[\"val_loss\"])\n",
    "    avg_val_acc = np.mean(fold_results[\"val_acc\"])\n",
    "        \n",
    "    return {\n",
    "        \"model_state_dict\": best_model_state,\n",
    "        \"avg_train_loss\": avg_train_loss,\n",
    "        \"avg_train_acc\": avg_train_acc,\n",
    "        \"avg_val_loss\": avg_val_loss,\n",
    "        \"avg_val_acc\": avg_val_acc,\n",
    "        \"hyperparameters\": {\n",
    "            \"batch_size\": batch_size,\n",
    "            \"learning_rate\": lr,\n",
    "            \"hidden_units\": hidden_units\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of epochs and the patience are kept relatively small to ensure that training time does not take too long. These (and more hyperparameters) can be adjusted to one's liking (and one's computing :))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do hyperparameter tuning with a simple feed forward neural network. Hopefully, it is now clear that it is worthwhile to make a clean training and validation pipeline before exploring more complex models. We will be using grid search for our hyperparameter search, and this is by no means exhaustive. Be sure to check out different variants than grid search and look at *which* hyperparameters you want to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product \n",
    "\n",
    "def hyperparameter_tuning(train_dataset, model_name, k, lrs, hidden_units_list):\n",
    "    all_results = []\n",
    "\n",
    "    for lr, hidden_units in product(lrs, hidden_units_list):\n",
    "        print(f\"Evaluating model with lr={lr}, hidden_units={hidden_units}\")\n",
    "        \n",
    "        results = cross_validation(k=k,\n",
    "                                train_dataset=train_dataset,\n",
    "                                model_name=model_name,\n",
    "                                lr=lr,\n",
    "                                hidden_units=hidden_units)\n",
    "        \n",
    "        all_results.append(results)\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, hidden_units):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(28*28, hidden_units)\n",
    "        self.layer2 = nn.Linear(hidden_units, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1, 28*28))\n",
    "        return self.layer2(self.relu(self.layer1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model with lr=0.05, hidden_units=64\n",
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:15<02:21, 15.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.6399 | train_acc: 84.1250 | val_loss: 0.3450 | val_acc: 90.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [00:31<02:04, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.3194 | train_acc: 90.8438 | val_loss: 0.2818 | val_acc: 92.0296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [00:46<01:49, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.2729 | train_acc: 92.2250 | val_loss: 0.2515 | val_acc: 92.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [00:51<01:59, 17.14s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m hidden_units_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Do cross validation with all combinations\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# In this case I only want 4 combinations, as it otherwise takes a LONG time to train\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# We can extend this search though, feel free to do so!\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m all_models_results \u001b[38;5;241m=\u001b[39m \u001b[43mhyperparameter_tuning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mffn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mlrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mhidden_units_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_units_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m, in \u001b[0;36mhyperparameter_tuning\u001b[1;34m(train_dataset, model_name, k, lrs, hidden_units_list)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lr, hidden_units \u001b[38;5;129;01min\u001b[39;00m product(lrs, hidden_units_list):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating model with lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, hidden_units=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_units\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mhidden_units\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_units\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_results\n",
      "Cell \u001b[1;32mIn[15], line 37\u001b[0m, in \u001b[0;36mcross_validation\u001b[1;34m(k, train_dataset, model_name, batch_size, lr, hidden_units)\u001b[0m\n\u001b[0;32m     34\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m     35\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m---> 37\u001b[0m results, best_epoch, best_model_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     45\u001b[0m fold_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m][best_epoch])\n\u001b[0;32m     46\u001b[0m fold_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m][best_epoch])\n",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, optimizer, loss_fn, epochs, patience, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m epochs_without_improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs)):\n\u001b[1;32m---> 24\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m test_step(model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     29\u001b[0m                                     data_loader\u001b[38;5;241m=\u001b[39mval_dataloader,\n\u001b[0;32m     30\u001b[0m                                     loss_fn\u001b[38;5;241m=\u001b[39mloss_fn)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     33\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, data_loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 9\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# We set the data to our device for faster computation.\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# We make the predictions\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:419\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:171\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    170\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 171\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    173\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "lrs = [0.05, 0.01]\n",
    "hidden_units_list = [64, 128]\n",
    "\n",
    "# Do cross validation with all combinations\n",
    "# In this case I only want 4 combinations, as it otherwise takes a LONG time to train\n",
    "# We can extend this search though, feel free to do so!\n",
    "\n",
    "all_models_results = hyperparameter_tuning(train_dataset=train_dataset,\n",
    "                                           model_name=\"ffn\",\n",
    "                                           k=k,\n",
    "                                           lrs=lrs,\n",
    "                                           hidden_units_list=hidden_units_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Hyperparameters: {'batch_size': 64, 'learning_rate': 0.05, 'hidden_units': 128}\n",
      "Best Validation Accuracy: 95.8943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the best model based on validation accuracy\n",
    "best_model_info = max(all_models_results, key=lambda x: x[\"avg_val_acc\"])\n",
    "\n",
    "print(f\"Best Model Hyperparameters: {best_model_info['hyperparameters']}\")\n",
    "print(f\"Best Validation Accuracy: {best_model_info['avg_val_acc']:.4f}\")\n",
    "\n",
    "# Load the best model for further evaluation or deployment\n",
    "best_ffn_model = return_model(\"ffn\", hidden_units=best_model_info[\"hyperparameters\"][\"hidden_units\"])\n",
    "best_ffn_model.load_state_dict(best_model_info[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare this to our baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:10<01:32, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 0.6214 | train_acc: 85.1583 | val_loss: 0.4239 | val_acc: 88.8146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [00:20<01:21, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 0.3944 | train_acc: 89.3542 | val_loss: 0.3690 | val_acc: 89.8771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [00:30<01:10, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 0.3582 | train_acc: 90.0542 | val_loss: 0.3457 | val_acc: 90.5021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [00:40<01:00, 10.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.3396 | train_acc: 90.5208 | val_loss: 0.3302 | val_acc: 90.9458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [00:50<00:50, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.3274 | train_acc: 90.8729 | val_loss: 0.3208 | val_acc: 91.1125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [01:01<00:41, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | train_loss: 0.3188 | train_acc: 91.2250 | val_loss: 0.3136 | val_acc: 91.2833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [01:11<00:30, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | train_loss: 0.3124 | train_acc: 91.3000 | val_loss: 0.3069 | val_acc: 91.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [01:21<00:20, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | train_loss: 0.3071 | train_acc: 91.4542 | val_loss: 0.3029 | val_acc: 91.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [01:31<00:10, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | train_loss: 0.3026 | train_acc: 91.6271 | val_loss: 0.2987 | val_acc: 91.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [01:41<00:00, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | train_loss: 0.2991 | train_acc: 91.6771 | val_loss: 0.2950 | val_acc: 91.7771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_results = cross_validation(k = 1,\n",
    "                                    train_dataset=train_dataset,\n",
    "                                    model_name=\"baseline\",\n",
    "                                    batch_size=64,\n",
    "                                    lr=0.05,\n",
    "                                    hidden_units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91.77708333333334, 95.89428191489363)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results[\"avg_val_acc\"], best_model_info[\"avg_val_acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there is a substantial improvement from our baseline model to our very simple feedforward neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet was the first 'modern' Convolutional Neural Network. I have edited it so that it works for 28 x 28 images. Now that we've made our entire pipeline, it is very easy to try models like these :)\n",
    "\n",
    "What is important to note about this is that we are now using Convolutional neural networks, which utilize the spatial relationships between the pixels. Our baseline model and simple FFN both do not look at this, as our images are flattened into vectors. This model is the first model which we cover that *doesn't* do this. This allows the model to find more intricate patterns in the images, and draws how we see the world! For more information on this, check out the wonderful chapter on CNNs: https://d2l.ai/chapter_convolutional-neural-networks/index.html \n",
    "\n",
    "We can use LazyLinear layers which allow us to only have to worry about the output dimensionality of each layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LazyConv2d(6, kernel_size=5, padding=2),\n",
    "            nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(16, kernel_size=5), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.LazyConv2d(24, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(24, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.LazyConv2d(16, kernel_size=3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "            nn.LazyLinear(256), nn.ReLU(), nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(128), nn.ReLU(),nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 1/10 [00:14<02:11, 14.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 2.3016 | train_acc: 11.1646 | val_loss: 2.3009 | val_acc: 11.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 2/10 [00:29<01:56, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | train_loss: 2.3011 | train_acc: 11.3562 | val_loss: 2.3001 | val_acc: 11.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 3/10 [00:43<01:39, 14.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | train_loss: 2.2705 | train_acc: 14.8708 | val_loss: 1.6812 | val_acc: 45.7021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 4/10 [00:56<01:24, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | train_loss: 0.8005 | train_acc: 73.7062 | val_loss: 0.3656 | val_acc: 88.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 5/10 [01:11<01:10, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | train_loss: 0.2522 | train_acc: 92.8979 | val_loss: 0.1264 | val_acc: 96.1375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 6/10 [01:25<00:56, 14.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | train_loss: 0.1552 | train_acc: 95.6437 | val_loss: 0.0894 | val_acc: 97.3438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 7/10 [01:39<00:42, 14.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | train_loss: 0.1252 | train_acc: 96.5396 | val_loss: 0.0788 | val_acc: 97.5396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 8/10 [01:52<00:27, 13.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | train_loss: 0.1028 | train_acc: 97.1562 | val_loss: 0.0584 | val_acc: 98.2958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 9/10 [02:06<00:13, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | train_loss: 0.0848 | train_acc: 97.6667 | val_loss: 0.0482 | val_acc: 98.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [02:20<00:00, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | train_loss: 0.0790 | train_acc: 97.8604 | val_loss: 0.0674 | val_acc: 97.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alexnet_results = cross_validation(k = 1,\n",
    "                                   train_dataset=train_dataset,\n",
    "                                   model_name=\"alexnet\",\n",
    "                                   batch_size=64,\n",
    "                                   lr=0.05,\n",
    "                                   hidden_units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91.77708333333334, 95.89428191489363, 98.53541666666666)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results[\"avg_val_acc\"], best_model_info[\"avg_val_acc\"], alexnet_results[\"avg_val_acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet does substantially better than the previous models. Even with little care about initialization, hyperparameters, etc. it did much, much better. This is the power of deep learning :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end of the intermediate MNIST-tutorial. I hope you learned something!\n",
    "\n",
    "We went through:\n",
    "- Model Implementation:\n",
    "We implemented a baseline model, a simple feedforward model, and a customized version of the AlexNet architecture adapted for 28x28 grayscale images (e.g., MNIST). We also used 'lazy' layers so that we do not have to worry about the input dimensionality of our layers. \n",
    "\n",
    "- Cross-Validation Setup:\n",
    "We set up a k-fold cross-validation framework that allows for a more robust measure of performance. \n",
    "\n",
    "- Training and Evaluation:\n",
    "We integrated early stopping into the training loop to prevent overfitting and reduce training time.\n",
    "We ensured that the model and data were properly moved to the appropriate device (CPU/GPU) for efficient computation.\n",
    "\n",
    "- Hyperparameter Tuning:\n",
    "We developed a hyperparameter tuning loop to evluate different combinations of learning rates and hidden units using cross-validation.\n",
    "We then stored the results of each hyperparameter configuration, allowing us to identify the best-performing model.\n",
    "\n",
    "Most importantly, we developed a robust pipeline! Do not underestimate how valuable it is to **start** with making a pipeline and a baseline model, and only then to try out your wildest architectures. Machine/Deep learning is all about reproducibility."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
